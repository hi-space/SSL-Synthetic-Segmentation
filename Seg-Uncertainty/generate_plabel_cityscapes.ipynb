{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import easydict\n",
        "import scipy\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import sys\n",
        "import re\n",
        "from packaging import version\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data, model_zoo\n",
        "from model.deeplab import Res_Deeplab\n",
        "from model.deeplab_multi import DeeplabMulti\n",
        "from model.deeplab_vgg import DeeplabVGG\n",
        "from dataset.cityscapes_dataset import cityscapesDataSet\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "from PIL import Image\n",
        "from utils.tool import fliplr\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import yaml\n",
        "\n",
        "from config import CONSTS\n",
        "\n",
        "torch.backends.cudnn.benchmark=True\n",
        "\n",
        "IMG_MEAN = np.array((104.00698793,116.66876762,122.67891434), dtype=np.float32)\n",
        "\n",
        "DATA_DIRECTORY = CONSTS.CITYSCAPES_PATH\n",
        "DATA_LIST_PATH = CONSTS.CITYSCAPES_TRAIN_LIST_PATH\n",
        "SAVE_PATH = CONSTS.CITYSCAPES_PSEUDO_PATH + 'train'\n",
        "\n",
        "if not os.path.isdir(CONSTS.CITYSCAPES_PSEUDO_PATH):\n",
        "    os.mkdir(CONSTS.CITYSCAPES_PSEUDO_PATH)\n",
        "    os.mkdir(SAVE_PATH)\n",
        "\n",
        "IGNORE_LABEL = 255\n",
        "NUM_CLASSES = 19\n",
        "NUM_STEPS = 2975 # Number of images in the validation set.\n",
        "# RESTORE_FROM = 'http://vllab.ucmerced.edu/ytsai/CVPR18/GTA2Cityscapes_multi-ed35151c.pth'\n",
        "# RESTORE_FROM_VGG = 'http://vllab.ucmerced.edu/ytsai/CVPR18/GTA2Cityscapes_vgg-ac4ac9f6.pth'\n",
        "# RESTORE_FROM_ORC = 'http://vllab1.ucmerced.edu/~whung/adaptSeg/cityscapes_oracle-b7b9934.pth'\n",
        "RESTORE_FROM = ''\n",
        "RESTORE_FROM_VGG = ''\n",
        "RESTORE_FROM_ORC = ''\n",
        "SET = 'train' # We generate pseudo label for training set\n",
        "\n",
        "MODEL = 'DeepLab'\n",
        "\n",
        "palette = [128, 64, 128, 244, 35, 232, 70, 70, 70, 102, 102, 156, 190, 153, 153, 153, 153, 153, 250, 170, 30,\n",
        "           220, 220, 0, 107, 142, 35, 152, 251, 152, 70, 130, 180, 220, 20, 60, 255, 0, 0, 0, 0, 142, 0, 0, 70,\n",
        "           0, 60, 100, 0, 80, 100, 0, 0, 230, 119, 11, 32]\n",
        "zero_pad = 256 * 3 - len(palette)\n",
        "for i in range(zero_pad):\n",
        "    palette.append(0)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_arguments():\n",
        "    args = easydict.EasyDict({\n",
        "        \"--model\": MODEL,\n",
        "        \"--data-dir\": DATA_DIRECTORY,\n",
        "        \"--data-list\": DATA_LIST_PATH,\n",
        "        \"--ignore-label\": IGNORE_LABEL,\n",
        "        \"--num-classes\": NUM_CLASSES,\n",
        "        \"--restore-from\": RESTORE_FROM,\n",
        "        \"--gpu\": 0,\n",
        "        \"--batchsize\": 12,\n",
        "        \"--set\": SET,\n",
        "        \"--save\": SAVE_PATH,\n",
        "    })\n",
        "    return args\n",
        "\n",
        "def colorize_mask(mask):\n",
        "    # mask: numpy array of the mask\n",
        "    new_mask = Image.fromarray(mask.astype(np.uint8)).convert('P')\n",
        "    new_mask.putpalette(palette)\n",
        "    return new_mask\n",
        "\n",
        "def save_heatmap(output_name):\n",
        "    output, name = output_name\n",
        "    fig = plt.figure()\n",
        "    plt.axis('off')\n",
        "    heatmap = plt.imshow(output, cmap='viridis')\n",
        "    fig.colorbar(heatmap)\n",
        "    fig.savefig('%s_heatmap.png' % (name.split('.jpg')[0]))\n",
        "    return\n",
        "\n",
        "def main():\n",
        "    \"\"\"Create the model and start the evaluation process.\"\"\"\n",
        "\n",
        "    args = get_arguments()\n",
        "\n",
        "    config_path = os.path.join(os.path.dirname(args.restore_from),'opts.yaml')\n",
        "    with open(config_path, 'r') as stream:\n",
        "        config = yaml.load(stream)\n",
        "\n",
        "    args.model = config['model']\n",
        "    print('ModelType:%s'%args.model)\n",
        "    print('NormType:%s'%config['norm_style'])\n",
        "    gpu0 = args.gpu\n",
        "    batchsize = args.batchsize\n",
        "\n",
        "    model_name = os.path.basename( os.path.dirname(args.restore_from) )\n",
        "    #args.save += model_name\n",
        "\n",
        "    if not os.path.exists(args.save):\n",
        "        os.makedirs(args.save)\n",
        "\n",
        "    if args.model == 'DeepLab':\n",
        "        model = DeeplabMulti(num_classes=args.num_classes, use_se = config['use_se'], train_bn = False, norm_style = config['norm_style'])\n",
        "    elif args.model == 'Oracle':\n",
        "        model = Res_Deeplab(num_classes=args.num_classes)\n",
        "        if args.restore_from == RESTORE_FROM:\n",
        "            args.restore_from = RESTORE_FROM_ORC\n",
        "    elif args.model == 'DeeplabVGG':\n",
        "        model = DeeplabVGG(num_classes=args.num_classes)\n",
        "        if args.restore_from == RESTORE_FROM:\n",
        "            args.restore_from = RESTORE_FROM_VGG\n",
        "\n",
        "    if args.restore_from[:4] == 'http' :\n",
        "        saved_state_dict = model_zoo.load_url(args.restore_from)\n",
        "    else:\n",
        "        saved_state_dict = torch.load(args.restore_from)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(saved_state_dict)\n",
        "    except:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "        model.load_state_dict(saved_state_dict)\n",
        "    model.eval()\n",
        "    model.cuda(gpu0)\n",
        "\n",
        "    testloader = data.DataLoader(cityscapesDataSet(args.data_dir, args.data_list, crop_size=(512, 1024), resize_size=(1024, 512), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                                    batch_size=batchsize, shuffle=False, pin_memory=True, num_workers=4)\n",
        "\n",
        "    scale = 1.25\n",
        "    testloader2 = data.DataLoader(cityscapesDataSet(args.data_dir, args.data_list, crop_size=(round(512*scale), round(1024*scale) ), resize_size=( round(1024*scale), round(512*scale)), mean=IMG_MEAN, scale=False, mirror=False, set=args.set),\n",
        "                                    batch_size=batchsize, shuffle=False, pin_memory=True, num_workers=4)\n",
        "\n",
        "\n",
        "    if version.parse(torch.__version__) >= version.parse('0.4.0'):\n",
        "        interp = nn.Upsample(size=(1024, 2048), mode='bilinear', align_corners=True)\n",
        "    else:\n",
        "        interp = nn.Upsample(size=(1024, 2048), mode='bilinear')\n",
        "\n",
        "    sm = torch.nn.Softmax(dim = 1)\n",
        "    log_sm = torch.nn.LogSoftmax(dim = 1)\n",
        "    kl_distance = nn.KLDivLoss( reduction = 'none')\n",
        "\n",
        "    for index, img_data in enumerate(zip(testloader, testloader2) ):\n",
        "        batch, batch2 = img_data\n",
        "        image, _, _, name = batch\n",
        "        image2, _, _, name2 = batch2\n",
        "        print(image.shape)\n",
        "\n",
        "        inputs = image.cuda()\n",
        "        inputs2 = image2.cuda()\n",
        "        print('\\r>>>>Extracting feature...%04d/%04d'%(index*batchsize, NUM_STEPS), end='')\n",
        "        if args.model == 'DeepLab':\n",
        "            with torch.no_grad():\n",
        "                output1, output2 = model(inputs)\n",
        "                output_batch = interp(sm(0.5* output1 + output2))\n",
        "\n",
        "                heatmap_batch = torch.sum(kl_distance(log_sm(output1), sm(output2)), dim=1)\n",
        "\n",
        "                output1, output2 = model(fliplr(inputs))\n",
        "                output1, output2 = fliplr(output1), fliplr(output2)\n",
        "                output_batch += interp(sm(0.5 * output1 + output2))\n",
        "                del output1, output2, inputs\n",
        "\n",
        "                output1, output2 = model(inputs2)\n",
        "                output_batch += interp(sm(0.5* output1 + output2))\n",
        "                output1, output2 = model(fliplr(inputs2))\n",
        "                output1, output2 = fliplr(output1), fliplr(output2)\n",
        "                output_batch += interp(sm(0.5 * output1 + output2))\n",
        "                del output1, output2, inputs2\n",
        "                output_batch = output_batch.cpu().data.numpy()\n",
        "                heatmap_batch = heatmap_batch.cpu().data.numpy()\n",
        "        elif args.model == 'DeeplabVGG' or args.model == 'Oracle':\n",
        "            output_batch = model(Variable(image).cuda())\n",
        "            output_batch = interp(output_batch).cpu().data.numpy()\n",
        "\n",
        "        #output_batch = output_batch.transpose(0,2,3,1)\n",
        "        #output_batch = np.asarray(np.argmax(output_batch, axis=3), dtype=np.uint8)\n",
        "        output_batch = output_batch.transpose(0,2,3,1)\n",
        "        score_batch = np.max(output_batch, axis=3)\n",
        "        output_batch = np.asarray(np.argmax(output_batch, axis=3), dtype=np.uint8)\n",
        "        #output_batch[score_batch<3.2] = 255  #3.2 = 4*0.8\n",
        "        for i in range(output_batch.shape[0]):\n",
        "            output = output_batch[i,:,:]\n",
        "            output_col = colorize_mask(output)\n",
        "            output = Image.fromarray(output)\n",
        "\n",
        "            name_tmp = name[i].split('/')[-1]\n",
        "            dir_name = name[i].split('/')[-2]\n",
        "            save_path = args.save + '/' + dir_name\n",
        "            #save_path = re.replace(save_path, 'leftImg8bit', 'pseudo')\n",
        "            #print(save_path)\n",
        "            if not os.path.isdir(save_path):\n",
        "                os.mkdir(save_path)\n",
        "            output.save('%s/%s' % (save_path, name_tmp))\n",
        "            print('%s/%s' % (save_path, name_tmp))\n",
        "            output_col.save('%s/%s_color.png' % (save_path, name_tmp.split('.')[0]))\n",
        "\n",
        "            heatmap_tmp = heatmap_batch[i,:,:]/np.max(heatmap_batch[i,:,:])\n",
        "            fig = plt.figure()\n",
        "            plt.axis('off')\n",
        "            heatmap = plt.imshow(heatmap_tmp, cmap='viridis')\n",
        "            fig.colorbar(heatmap)\n",
        "            fig.savefig('%s/%s_heatmap.png' % (save_path, name_tmp.split('.')[0]))\n",
        "            \n",
        "    return args.save"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with torch.no_grad():\n",
        "    save_path = main()\n",
        "os.system('python compute_iou.py ./data/Cityscapes/data/gtFine/train %s'%save_path)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}