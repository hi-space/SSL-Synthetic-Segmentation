{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data, model_zoo\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import scipy.misc\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import time\n",
        "import yaml\n",
        "import easydict\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from trainer_ms import AD_Trainer\n",
        "from utils.loss import CrossEntropy2d\n",
        "from utils.tool import adjust_learning_rate, adjust_learning_rate_D, Timer \n",
        "from dataset.gta5_dataset import GTA5DataSet\n",
        "from dataset.cityscapes_dataset import cityscapesDataSet\n",
        "\n",
        "from config import CONSTS\n",
        "\n",
        "IMG_MEAN = np.array((104.00698793, 116.66876762, 122.67891434), dtype=np.float32)\n",
        "\n",
        "AUTOAUG = False\n",
        "AUTOAUG_TARGET = False\n",
        "\n",
        "MODEL = 'DeepLab'\n",
        "BATCH_SIZE = 16\n",
        "ITER_SIZE = 1\n",
        "NUM_WORKERS = 2\n",
        "DATA_DIRECTORY = CONSTS.GTA_PATH\n",
        "DATA_LIST_PATH = CONSTS.GTA_TRAIN_LIST_PATH\n",
        "DROPRATE = 0.1\n",
        "IGNORE_LABEL = 255\n",
        "INPUT_SIZE = '1280,720'\n",
        "DATA_DIRECTORY_TARGET = CONSTS.CITYSCAPES_PATH\n",
        "DATA_LIST_PATH_TARGET = CONSTS.CITYSCAPES_TRAIN_LIST_PATH\n",
        "INPUT_SIZE_TARGET = '1024,512'\n",
        "CROP_SIZE = '384,192' # 640,360\n",
        "LEARNING_RATE = 2.5e-4\n",
        "MOMENTUM = 0.9\n",
        "MAX_VALUE = 2\n",
        "NUM_CLASSES = 19\n",
        "NUM_STEPS = 100000\n",
        "NUM_STEPS_STOP = 100000  # early stopping\n",
        "POWER = 0.9\n",
        "RANDOM_SEED = 1234\n",
        "RESTORE_FROM = 'http://vllab.ucmerced.edu/ytsai/CVPR18/DeepLab_resnet_pretrained_init-f81d91e8.pth'\n",
        "SAVE_NUM_IMAGES = 2\n",
        "SAVE_PRED_EVERY = 5000\n",
        "SNAPSHOT_DIR = './snapshots/'\n",
        "WEIGHT_DECAY = 0.0005\n",
        "WARM_UP = 0 # no warmup\n",
        "LOG_DIR = './log'\n",
        "\n",
        "LEARNING_RATE_D = 1e-4\n",
        "LAMBDA_SEG = 0.1\n",
        "LAMBDA_ADV_TARGET1 = 0.0002\n",
        "LAMBDA_ADV_TARGET2 = 0.001\n",
        "\n",
        "LAMBDA_ME_TARGET = 0\n",
        "LAMBDA_KL_TARGET = 0\n",
        "\n",
        "TARGET = 'cityscapes'\n",
        "SET = 'train'\n",
        "NORM_STYLE = 'bn' # or in"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_arguments():\n",
        "    \"\"\"Parse all the arguments provided from the CLI.\n",
        "\n",
        "    Returns:\n",
        "      A list of parsed arguments.\n",
        "    \"\"\"\n",
        "    args = easydict.EasyDict({\n",
        "        \"autoaug\": True,\n",
        "        \"autoaug_target\": True,\n",
        "        \"model\": MODEL,\n",
        "        \"batch-size\": BATCH_SIZE,\n",
        "        \"iter-size\": ITER_SIZE,\n",
        "        \"num-workers\": NUM_WORKERS,\n",
        "        \"data-dir\": DATA_DIRECTORY,\n",
        "        \"data-list\": DATA_LIST_PATH,\n",
        "        \"droprate\": DROPRATE,\n",
        "        \"ignore-label\": IGNORE_LABEL,\n",
        "        \"input-size\": INPUT_SIZE,\n",
        "        \"crop-size\": CROP_SIZE,\n",
        "        \"data-dir-target\": DATA_DIRECTORY_TARGET,\n",
        "        \"data-list-target\": DATA_LIST_PATH_TARGET,\n",
        "        \"input-size-target\": INPUT_SIZE_TARGET,\n",
        "        \"is-training\": True,\n",
        "        \"learning-rate\": LEARNING_RATE, # Base learning rate for training with polynomial decay.\n",
        "        \"learning-rate-D\": LEARNING_RATE_D, # Base learning rate for discriminator\n",
        "        \"lambda-seg\": LAMBDA_SEG,\n",
        "        \"lambda-adv-target1\": LAMBDA_ADV_TARGET1,\n",
        "        \"lambda-adv-target2\": LAMBDA_ADV_TARGET2,\n",
        "        \"lambda-me-target\": LAMBDA_ME_TARGET,\n",
        "        \"lambda-kl-target\":LAMBDA_KL_TARGET,\n",
        "        \"momentum\": MOMENTUM,\n",
        "        \"max-value\": MAX_VALUE,\n",
        "        \"norm-style\": NORM_STYLE,\n",
        "        \"lambda-me-target\": LAMBDA_ME_TARGET,\n",
        "        \"lambda-kl-target\": LAMBDA_KL_TARGET,\n",
        "        \"momentum\": MOMENTUM,\n",
        "        \"max-value\": MAX_VALUE,\n",
        "        \"norm-style\": NORM_STYLE,\n",
        "        \"not-restore-last\": True,\n",
        "        \"num-classes\": NUM_CLASSES,\n",
        "        \"num-steps\": NUM_STEPS,\n",
        "        \"num-steps-stop\": NUM_STEPS_STOP,\n",
        "        \"power\": POWER,\n",
        "        \"random-mirror\": True,\n",
        "        \"random-scale\": True,\n",
        "        \"fp16\": True,\n",
        "        \"random-seed\": RANDOM_SEED,\n",
        "        \"restore-from\": RESTORE_FROM,\n",
        "        \"save-num-images\": SAVE_NUM_IMAGES,\n",
        "        \"save-pred-every\": SAVE_PRED_EVERY,\n",
        "        \"snapshot-dir\": SNAPSHOT_DIR,\n",
        "        \"weight-decay\": WEIGHT_DECAY,\n",
        "        \"warm-up\": WARM_UP,\n",
        "        \"cpu\": True,\n",
        "        \"class-balance\": True,\n",
        "        \"use-se\": True,\n",
        "        \"only-hard-label\": 0,\n",
        "        \"train_bn\": True,\n",
        "        \"sync_bn\": True,\n",
        "        \"often-balance\": True,\n",
        "        \"gpu-ids\": '0',\n",
        "        \"tensorboard\": True,\n",
        "        \"log-dir\": LOG_DIR,\n",
        "        \"set\": SET,\n",
        "        \"multi_gpu\": False,\n",
        "    })   \n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "args = get_arguments()\n",
        "\n",
        "# save opts\n",
        "if not os.path.exists(args.snapshot_dir):\n",
        "    os.makedirs(args.snapshot_dir)\n",
        "\n",
        "with open('%s/opts.yaml'%args.snapshot_dir, 'w') as fp:\n",
        "    yaml.dump(vars(args), fp, default_flow_style=False)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Create the model and start the training.\"\"\"\n",
        "\n",
        "    w, h = map(int, args.input_size.split(','))\n",
        "    args.input_size = (w, h)\n",
        "\n",
        "    w, h = map(int, args.crop_size.split(','))\n",
        "    args.crop_size = (h, w)\n",
        "\n",
        "    w, h = map(int, args.input_size_target.split(','))\n",
        "    args.input_size_target = (w, h)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "\n",
        "    str_ids = args.gpu_ids.split(',')\n",
        "    gpu_ids = []\n",
        "    for str_id in str_ids:\n",
        "        gid = int(str_id)\n",
        "        if gid >=0:\n",
        "            gpu_ids.append(gid)\n",
        "\n",
        "    num_gpu = len(gpu_ids)\n",
        "\n",
        "    if num_gpu>1:\n",
        "        args.multi_gpu = True\n",
        "        Trainer = AD_Trainer(args)\n",
        "        Trainer.G = torch.nn.DataParallel( Trainer.G, gpu_ids)\n",
        "        Trainer.D1 = torch.nn.DataParallel( Trainer.D1, gpu_ids)\n",
        "        Trainer.D2 = torch.nn.DataParallel( Trainer.D2, gpu_ids)\n",
        "    else:\n",
        "        Trainer = AD_Trainer(args)\n",
        "\n",
        "    print(Trainer)\n",
        "\n",
        "    trainloader = data.DataLoader(\n",
        "        GTA5DataSet(args.data_dir, args.data_list, max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                    resize_size=args.input_size,\n",
        "                    crop_size=args.crop_size,\n",
        "                    scale=True, mirror=True, mean=IMG_MEAN, autoaug = args.autoaug),\n",
        "        batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "    trainloader_iter = enumerate(trainloader)\n",
        "\n",
        "    targetloader = data.DataLoader(cityscapesDataSet(args.data_dir_target, args.data_list_target,\n",
        "                                                     max_iters=args.num_steps * args.iter_size * args.batch_size,\n",
        "                                                     resize_size=args.input_size_target,\n",
        "                                                     crop_size=args.crop_size,\n",
        "                                                     scale=False, mirror=args.random_mirror, mean=IMG_MEAN,\n",
        "                                                     set=args.set, autoaug = args.autoaug_target),\n",
        "                                   batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers,\n",
        "                                   pin_memory=True, drop_last=True)\n",
        "\n",
        "\n",
        "    targetloader_iter = enumerate(targetloader)\n",
        "\n",
        "    # set up tensor board\n",
        "    if args.tensorboard:\n",
        "        args.log_dir += '/'+ os.path.basename(args.snapshot_dir)\n",
        "        if not os.path.exists(args.log_dir):\n",
        "            os.makedirs(args.log_dir)\n",
        "\n",
        "        writer = SummaryWriter(args.log_dir)\n",
        "\n",
        "    for i_iter in range(args.num_steps):\n",
        "\n",
        "        loss_seg_value1 = 0\n",
        "        loss_adv_target_value1 = 0\n",
        "        loss_D_value1 = 0\n",
        "\n",
        "        loss_seg_value2 = 0\n",
        "        loss_adv_target_value2 = 0\n",
        "        loss_D_value2 = 0\n",
        "\n",
        "\n",
        "        adjust_learning_rate(Trainer.gen_opt , i_iter, args)\n",
        "        adjust_learning_rate_D(Trainer.dis1_opt, i_iter, args)\n",
        "        adjust_learning_rate_D(Trainer.dis2_opt, i_iter, args)\n",
        "\n",
        "        for sub_i in range(args.iter_size):\n",
        "\n",
        "            # train G\n",
        "\n",
        "            # train with source\n",
        "\n",
        "            _, batch = trainloader_iter.__next__()\n",
        "            _, batch_t = targetloader_iter.__next__()\n",
        "\n",
        "            images, labels, _, _ = batch\n",
        "            images = images.cuda()\n",
        "            labels = labels.long().cuda()\n",
        "            images_t, labels_t, _, _ = batch_t\n",
        "            images_t = images_t.cuda()\n",
        "            labels_t = labels_t.long().cuda()\n",
        "\n",
        "            with Timer(\"Elapsed time in update: %f\"):\n",
        "                loss_seg1, loss_seg2, loss_adv_target1, loss_adv_target2, loss_me, loss_kl, pred1, pred2, pred_target1, pred_target2, val_loss = Trainer.gen_update(images, images_t, labels, labels_t, i_iter)\n",
        "                loss_seg_value1 += loss_seg1.item() / args.iter_size\n",
        "                loss_seg_value2 += loss_seg2.item() / args.iter_size\n",
        "                loss_adv_target_value1 += loss_adv_target1 / args.iter_size\n",
        "                loss_adv_target_value2 += loss_adv_target2 / args.iter_size\n",
        "                loss_me_value = loss_me\n",
        "\n",
        "                if args.lambda_adv_target1 > 0 and args.lambda_adv_target2 > 0:\n",
        "                    loss_D1, loss_D2 = Trainer.dis_update(pred1, pred2, pred_target1, pred_target2)\n",
        "                    loss_D_value1 += loss_D1.item()\n",
        "                    loss_D_value2 += loss_D2.item()\n",
        "                else:\n",
        "                    loss_D_value1 = 0\n",
        "                    loss_D_value2 = 0\n",
        "\n",
        "        del pred1, pred2, pred_target1, pred_target2\n",
        "\n",
        "        if args.tensorboard:\n",
        "            scalar_info = {\n",
        "                'loss_seg1': loss_seg_value1,\n",
        "                'loss_seg2': loss_seg_value2,\n",
        "                'loss_adv_target1': loss_adv_target_value1,\n",
        "                'loss_adv_target2': loss_adv_target_value2,\n",
        "                'loss_me_target': loss_me_value,\n",
        "                'loss_kl_target': loss_kl,\n",
        "                'loss_D1': loss_D_value1,\n",
        "                'loss_D2': loss_D_value2,\n",
        "                'val_loss': val_loss,\n",
        "            }\n",
        "\n",
        "            if i_iter % 100 == 0:\n",
        "                for key, val in scalar_info.items():\n",
        "                    writer.add_scalar(key, val, i_iter)\n",
        "\n",
        "        print('exp = {}'.format(args.snapshot_dir))\n",
        "        print(\n",
        "        '\\033[1m iter = %8d/%8d \\033[0m loss_seg1 = %.3f loss_seg2 = %.3f loss_me = %.3f  loss_kl = %.3f loss_adv1 = %.3f, loss_adv2 = %.3f loss_D1 = %.3f loss_D2 = %.3f, val_loss=%.3f'%(i_iter, args.num_steps, loss_seg_value1, loss_seg_value2, loss_me_value, loss_kl, loss_adv_target_value1, loss_adv_target_value2, loss_D_value1, loss_D_value2, val_loss))\n",
        "\n",
        "        # clear loss\n",
        "        del loss_seg1, loss_seg2, loss_adv_target1, loss_adv_target2, loss_me, loss_kl, val_loss\n",
        "\n",
        "        if i_iter >= args.num_steps_stop - 1:\n",
        "            print('save model ...')\n",
        "            torch.save(Trainer.G.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(args.num_steps_stop) + '.pth'))\n",
        "            torch.save(Trainer.D1.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(args.num_steps_stop) + '_D1.pth'))\n",
        "            torch.save(Trainer.D2.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(args.num_steps_stop) + '_D2.pth'))\n",
        "            break\n",
        "\n",
        "        if i_iter % args.save_pred_every == 0 and i_iter != 0:\n",
        "            print('taking snapshot ...')\n",
        "            torch.save(Trainer.G.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(i_iter) + '.pth'))\n",
        "            torch.save(Trainer.D1.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(i_iter) + '_D1.pth'))\n",
        "            torch.save(Trainer.D2.state_dict(), osp.join(args.snapshot_dir, 'GTA5_' + str(i_iter) + '_D2.pth'))\n",
        "\n",
        "    if args.tensorboard:\n",
        "        writer.close()\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "main()"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}